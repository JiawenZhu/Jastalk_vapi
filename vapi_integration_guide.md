# ğŸ¤ Vapi è¯­éŸ³é¢è¯•å®Œæ•´é›†æˆæŒ‡å—

## ğŸ“‹ ç›®å½•
1. [å‰ç½®å‡†å¤‡](#å‰ç½®å‡†å¤‡)
2. [å®‰è£…å’Œé…ç½®](#å®‰è£…å’Œé…ç½®)
3. [é›†æˆæ­¥éª¤](#é›†æˆæ­¥éª¤)
4. [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§)
5. [æµ‹è¯•å’Œè°ƒè¯•](#æµ‹è¯•å’Œè°ƒè¯•)
6. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ”§ å‰ç½®å‡†å¤‡

### 1. è·å– Vapi API Keys

1. è®¿é—® [Vapi Dashboard](https://dashboard.vapi.ai/)
2. æ³¨å†Œ/ç™»å½•è´¦æˆ·
3. è¿›å…¥ **Settings â†’ API Keys**
4. å¤åˆ¶ä»¥ä¸‹å¯†é’¥ï¼š
   - **Public Key** (pk_xxx): ç”¨äºå‰ç«¯
   - **Private Key** (sk_xxx): ç”¨äºåç«¯ MCP

### 2. æ‰€éœ€æƒé™

ç¡®ä¿æµè§ˆå™¨æˆäºˆä»¥ä¸‹æƒé™ï¼š
- âœ… éº¦å…‹é£è®¿é—®
- âœ… éŸ³é¢‘æ’­æ”¾
- âœ… ç½‘ç»œè¿æ¥

---

## ğŸ“¦ å®‰è£…å’Œé…ç½®

### Step 1: å®‰è£…ä¾èµ–

```bash
# å®‰è£… Vapi Web SDK
npm install @vapi-ai/web

# æˆ–ä½¿ç”¨ yarn
yarn add @vapi-ai/web
```

### Step 2: åœ¨ HTML ä¸­å¼•å…¥ (CDN æ–¹å¼)

```html
<!DOCTYPE html>
<html>
<head>
    <title>Interview Agent</title>
    <!-- Vapi SDK -->
    <script src="https://cdn.jsdelivr.net/npm/@vapi-ai/web@latest/dist/index.js"></script>
</head>
<body>
    <div id="root"></div>
    <script>
        // åˆå§‹åŒ– Vapi
        const VAPI_PUBLIC_KEY = 'YOUR_PUBLIC_KEY_HERE';
        const vapi = new window.Vapi(VAPI_PUBLIC_KEY);
    </script>
</body>
</html>
```

### Step 3: ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
# Vapi Keys
VAPI_PUBLIC_KEY=pk_your_public_key_here
VAPI_PRIVATE_KEY=sk_your_private_key_here

# OpenAI (ç”¨äº Vapi Assistant)
OPENAI_API_KEY=sk-your-openai-key
```

---

## ğŸš€ é›†æˆæ­¥éª¤

### 1. åˆå§‹åŒ– Vapi

```javascript
import Vapi from '@vapi-ai/web';

// åˆå§‹åŒ– Vapi å®¢æˆ·ç«¯
const vapi = new Vapi('YOUR_PUBLIC_KEY');

// è®¾ç½®äº‹ä»¶ç›‘å¬
vapi.on('call-start', () => console.log('Interview started'));
vapi.on('call-end', () => console.log('Interview ended'));
vapi.on('message', (msg) => console.log('Message:', msg));
vapi.on('error', (err) => console.error('Error:', err));
```

### 2. åˆ›å»ºé¢è¯• Assistant

```javascript
const createInterviewAssistant = (questions, language = 'en') => {
  return {
    model: {
      provider: "openai",
      model: "gpt-4",
      messages: [{
        role: "system",
        content: `You are conducting an interview. 
        
Questions to ask:
${questions.map((q, i) => `${i+1}. ${q}`).join('\n')}

Ask one question at a time and wait for responses.`
      }]
    },
    voice: {
      provider: "playht",
      voiceId: language === 'zh' ? 'zh-CN-XiaoxiaoNeural' : 'jennifer-playht'
    },
    transcriber: {
      provider: "deepgram",
      model: "nova-2",
      language: language
    },
    firstMessage: "Hello! Welcome to your interview. Are you ready to begin?",
    recordingEnabled: true
  };
};
```

### 3. å¼€å§‹è¯­éŸ³é¢è¯•

```javascript
async function startVoiceInterview(questions) {
  try {
    // åˆ›å»º assistant é…ç½®
    const assistant = createInterviewAssistant(questions, 'en');
    
    // å¼€å§‹é€šè¯
    await vapi.start(assistant);
    
    console.log('Voice interview started!');
  } catch (error) {
    console.error('Failed to start interview:', error);
    alert('Please allow microphone access');
  }
}
```

### 4. å®æ—¶è½¬å½•å¤„ç†

```javascript
// ç›‘å¬ç”¨æˆ·è¯­éŸ³è½¬å½•
vapi.on('message', (message) => {
  if (message.type === 'transcript' && message.role === 'user') {
    console.log('User said:', message.transcript);
    
    // ä¿å­˜ç”¨æˆ·å›ç­”
    saveUserAnswer(message.transcript);
  }
  
  if (message.type === 'transcript' && message.role === 'assistant') {
    console.log('Interviewer asked:', message.transcript);
    
    // æ˜¾ç¤ºé¢è¯•å®˜é—®é¢˜
    displayInterviewerQuestion(message.transcript);
  }
});
```

### 5. ç»“æŸé¢è¯•

```javascript
function endVoiceInterview() {
  vapi.stop();
  console.log('Interview ended');
}
```

---

## âœ¨ åŠŸèƒ½ç‰¹æ€§

### 1. **å®æ—¶è¯­éŸ³è¯†åˆ«**
- ğŸ¤ è‡ªåŠ¨å°†è¯­éŸ³è½¬ä¸ºæ–‡å­—
- ğŸŒ æ”¯æŒå¤šè¯­è¨€ï¼ˆè‹±è¯­ã€ä¸­æ–‡ã€è¥¿ç­ç‰™è¯­ï¼‰
- âš¡ ä½å»¶è¿Ÿï¼ˆ< 500msï¼‰

### 2. **AI é¢è¯•å®˜**
- ğŸ¤– GPT-4 é©±åŠ¨çš„æ™ºèƒ½å¯¹è¯
- ğŸ“ è‡ªåŠ¨è¿½é—®å’Œåé¦ˆ
- ğŸ¯ åŸºäºé—®é¢˜åˆ—è¡¨çš„ç»“æ„åŒ–é¢è¯•

### 3. **éŸ³é¢‘å¯è§†åŒ–**
- ğŸ“Š å®æ—¶éŸ³é‡æŒ‡ç¤ºå™¨
- ğŸ”Š è¯´è¯çŠ¶æ€æ£€æµ‹
- ğŸ“ˆ è¯­éŸ³æ´»åŠ¨å¯è§†åŒ–

### 4. **è½¬å½•å’Œè®°å½•**
- ğŸ’¾ è‡ªåŠ¨ä¿å­˜æ‰€æœ‰å¯¹è¯
- ğŸ“„ å®æ—¶æ˜¾ç¤ºè½¬å½•æ–‡æœ¬
- ğŸ” å¯æœç´¢çš„é¢è¯•è®°å½•

---

## ğŸ§ª æµ‹è¯•å’Œè°ƒè¯•

### æµ‹è¯•è¯­éŸ³åŠŸèƒ½

```javascript
// æµ‹è¯•éº¦å…‹é£
async function testMicrophone() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    console.log('âœ… Microphone access granted');
    stream.getTracks().forEach(track => track.stop());
    return true;
  } catch (error) {
    console.error('âŒ Microphone access denied:', error);
    return false;
  }
}

// æµ‹è¯• Vapi è¿æ¥
async function testVapiConnection() {
  try {
    const vapi = new Vapi('YOUR_PUBLIC_KEY');
    console.log('âœ… Vapi initialized successfully');
    return true;
  } catch (error) {
    console.error('âŒ Vapi initialization failed:', error);
    return false;
  }
}
```

### è°ƒè¯•æŠ€å·§

1. **æŸ¥çœ‹æ§åˆ¶å°æ—¥å¿—**
```javascript
vapi.on('message', (msg) => {
  console.log('ğŸ“¨ Message:', JSON.stringify(msg, null, 2));
});
```

2. **ç›‘æ§ç½‘ç»œè¯·æ±‚**
- æ‰“å¼€ Chrome DevTools â†’ Network
- ç­›é€‰ WebSocket è¿æ¥
- æŸ¥çœ‹ Vapi API è°ƒç”¨

3. **æµ‹è¯•ä¸åŒè¯­è¨€**
```javascript
// è‹±è¯­
const enAssistant = createInterviewAssistant(questions, 'en');

// ä¸­æ–‡
const zhAssistant = createInterviewAssistant(questions, 'zh');

// è¥¿ç­ç‰™è¯­
const esAssistant = createInterviewAssistant(questions, 'es');
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ:**
1. æ£€æŸ¥æµè§ˆå™¨è®¾ç½® â†’ éšç§ â†’ éº¦å…‹é£
2. ç¡®ä¿ç½‘ç«™æœ‰éº¦å…‹é£æƒé™
3. åˆ·æ–°é¡µé¢é‡æ–°è¯·æ±‚æƒé™

### Q2: è¯­éŸ³è¯†åˆ«ä¸å‡†ç¡®ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ:**
1. ä½¿ç”¨é«˜è´¨é‡éº¦å…‹é£
2. åœ¨å®‰é™ç¯å¢ƒä¸­æµ‹è¯•
3. è°ƒæ•´ `endOfSpeechSensitivity` å‚æ•°
4. ä½¿ç”¨ Deepgram `nova-2` æ¨¡å‹

### Q3: é€šè¯çªç„¶æ–­å¼€ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ:**
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. è®¾ç½®åˆç†çš„ `maxDurationSeconds`
3. å¤„ç† `error` äº‹ä»¶å¹¶é‡è¿

### Q4: å¦‚ä½•ä¿å­˜é¢è¯•è®°å½•ï¼Ÿ

```javascript
let interviewTranscript = [];

vapi.on('message', (message) => {
  if (message.type === 'transcript') {
    interviewTranscript.push({
      role: message.role,
      text: message.transcript,
      timestamp: new Date().toISOString()
    });
  }
});

// ä¿å­˜åˆ°æœ¬åœ°
vapi.on('call-end', () => {
  localStorage.setItem('interview_transcript', 
    JSON.stringify(interviewTranscript)
  );
});
```

### Q5: å¦‚ä½•åˆ‡æ¢è¯­è¨€ï¼Ÿ

```javascript
// åŠ¨æ€åˆ‡æ¢è¯­è¨€
const assistantConfig = {
  ...baseConfig,
  voice: {
    provider: "playht",
    voiceId: currentLang === 'zh' ? 'zh-CN-XiaoxiaoNeural' : 
             currentLang === 'es' ? 'es-MX-DaliaNeural' : 
             'jennifer-playht'
  },
  transcriber: {
    provider: "deepgram",
    model: "nova-2",
    language: currentLang
  }
};
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. å‡å°‘å»¶è¿Ÿ
```javascript
const optimizedConfig = {
  ...assistantConfig,
  endOfSpeechSensitivity: 0.7, // æ›´å¿«æ£€æµ‹è¯´è¯ç»“æŸ
  backgroundSound: "off", // å…³é—­èƒŒæ™¯éŸ³
  model: {
    ...model,
    temperature: 0.5 // æ›´ç¡®å®šæ€§çš„å“åº”
  }
};
```

### 2. èŠ‚çœæˆæœ¬
```javascript
// ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹
const costEffectiveConfig = {
  model: {
    provider: "openai",
    model: "gpt-3.5-turbo", // ä»£æ›¿ gpt-4
    ...
  },
  voice: {
    provider: "11labs", // æˆ–å…¶ä»–æä¾›å•†
    voiceId: "..."
  }
};
```

---

## ğŸ”’ å®‰å…¨æœ€ä½³å®è·µ

1. âœ… **Never** expose Private Key in frontend
2. âœ… Use environment variables for keys
3. âœ… Implement rate limiting
4. âœ… Validate all user inputs
5. âœ… Use HTTPS for all connections

---

## ğŸ“š æ›´å¤šèµ„æº

- [Vapi å®˜æ–¹æ–‡æ¡£](https://docs.vapi.ai/)
- [Vapi Web SDK](https://github.com/VapiAI/web)
- [ç¤ºä¾‹ä»£ç ](https://github.com/VapiAI/examples)
- [ç¤¾åŒºæ”¯æŒ](https://discord.gg/vapi)

---

## ğŸ¯ ä¸‹ä¸€æ­¥

1. âœ… é›†æˆåˆ°ä½ çš„åº”ç”¨
2. âœ… æµ‹è¯•æ‰€æœ‰åŠŸèƒ½
3. âœ… ä¼˜åŒ–ç”¨æˆ·ä½“éªŒ
4. âœ… éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

Good luck! ğŸš€
